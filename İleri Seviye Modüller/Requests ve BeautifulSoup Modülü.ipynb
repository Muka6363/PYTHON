{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests ve BeautifulSoup Modülü\n",
    "\n",
    "\n",
    "Bu videoda internetten veri çekmemizi ve bu verileri parçalamamızı sağlayan ***requests*** ve ***BeautifulSoup*** modüllerini öğreneceğiz. Ancak bu modüller Python ile hazır gelmediğinden ilk olarak bunları internetten indirmemiz gerekiyor.\n",
    "\n",
    "### Windows üzerinde kurulum\n",
    "\n",
    "Windows üzerinde bu iki modulü indirmemiz için cmd'yi açıyoruz ve şu iki komutu sırayla çalıştırıyoruz.\n",
    "\n",
    "***pip3 install requests***\n",
    "\n",
    "***pip3 install beautifulsoup4***\n",
    "\n",
    "\n",
    "Bunları çalıştırdığımız zaman requests ve beautifulsoup kurulmuş olacak.\n",
    "\n",
    "*Kurulumda herhangi bir sıkıntı yaşarsanız çekinmeden sorabilirsiniz.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubuntu üzerinde kurulum \n",
    "\n",
    "Terminali açın ve ilk önce şu komutu çalıştırın.\n",
    "\n",
    "***sudo apt-get install python-setuptools***\n",
    "\n",
    "Daha sonra şu komutları çalıştırın.\n",
    "\n",
    "***sudo pip3 install requests***\n",
    "\n",
    "***sudo pip3 install beautifulsoup4***\n",
    "\n",
    "\n",
    "*Kurulumda herhangi bir sıkıntı yaşarsanız çekinmeden sorabilirsiniz.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artık internet sayfalarındaki verileri parçalamaya başlayabiliriz. Ancak videoya başlamadan önce sıkıntı yaşamamak için ***html etiketlerinden div,table, td, tr , a gibi etiketlere*** biraz göz gezdirebilirsiniz.\n",
    "\n",
    "Şu siteler faydalı olabilir;\n",
    "\n",
    "*http://www.htmldersleri.org/index.php?getir=html_intro&ID=1*\n",
    "\n",
    "*http://www.htmldersleri.org/index.php?getir=html_links&ID=7*\n",
    "\n",
    "*http://www.htmldersleri.org/index.php?getir=html_attributes&ID=4*\n",
    "\n",
    "*http://www.htmldersleri.org/index.php?getir=html_tables&ID=9*\n",
    "\n",
    "Güzel ! Her şey tamamlandığına göre dersimize başlayabiliriz.\n",
    "\n",
    "*Kodlarımızı bilgisayarımızda çalıştıracağız.*\n",
    "\n",
    "\n",
    "#### Web Sayfası Kaynağını  Alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =  \"https://yellowpages.com.tr/ara?q=Ankara\" # Site linkimiz \n",
    "\n",
    "response =  requests.get(url) # Web sayfamızı çekiyoruz.\n",
    "\n",
    "html_icerigi = response.content  # Web sayfamızın içeriğini alıyoruz.\n",
    "\n",
    "soup =  BeautifulSoup(html_icerigi,\"html.parser\") # Web sayfamızı parçalamak için BeautifulSoup objesine atıyoruz.\n",
    "\n",
    "\n",
    "print(soup.prettify()) # Daha güzel bir görüntü için prettify() fonksiyonunu kullanıyoruz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Sayfasındaki < a > etiketlerini alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =  \"https://yellowpages.com.tr/ara?q=Ankara\" # Site linkimiz \n",
    "\n",
    "response =  requests.get(url) # Web sayfamızı çekiyoruz.\n",
    "\n",
    "html_icerigi = response.content  # Web sayfamızın içeriğini alıyoruz.\n",
    "\n",
    "soup =  BeautifulSoup(html_icerigi,\"html.parser\") # Web sayfamızı parçalamak için BeautifulSoup objesine atıyoruz.\n",
    "\n",
    "\n",
    "print(soup.find_all(\"a\")) # Bize tüm <a> etiketlerini liste şeklinde dönüyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### < a > etiketlerinin içindeki \"href\" değerlerini alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =  \"https://yellowpages.com.tr/ara?q=Ankara\" # Site linkimiz \n",
    "\n",
    "response =  requests.get(url) # Web sayfamızı çekiyoruz.\n",
    "\n",
    "html_icerigi = response.content  # Web sayfamızın içeriğini alıyoruz.\n",
    "\n",
    "soup =  BeautifulSoup(html_icerigi,\"html.parser\") # Web sayfamızı parçalamak için BeautifulSoup objesine atıyoruz.\n",
    "\n",
    "\n",
    "for i in soup.find_all(\"a\"):\n",
    "    print(i.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### < a > etiketlerinin içindeki yazı değerlerini alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =  \"https://yellowpages.com.tr/ara?q=Ankara\" # Site linkimiz \n",
    "\n",
    "response =  requests.get(url) # Web sayfamızı çekiyoruz.\n",
    "\n",
    "html_icerigi = response.content  # Web sayfamızın içeriğini alıyoruz.\n",
    "\n",
    "soup =  BeautifulSoup(html_icerigi,\"html.parser\") # Web sayfamızı parçalamak için BeautifulSoup objesine atıyoruz.\n",
    "\n",
    "\n",
    "for i in soup.find_all(\"a\"):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class değerleri \"yp-poi-box-2\" olan < div > etiketlerini alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =  \"https://yellowpages.com.tr/ara?q=Ankara\" # Site linkimiz \n",
    "\n",
    "response =  requests.get(url) # Web sayfamızı çekiyoruz.\n",
    "\n",
    "html_icerigi = response.content  # Web sayfamızın içeriğini alıyoruz.\n",
    "\n",
    "soup =  BeautifulSoup(html_icerigi,\"html.parser\") # Web sayfamızı parçalamak için BeautifulSoup objesine atıyoruz.\n",
    "\n",
    " # Bu kullanımın anlamı div etiketlerinden class'ı yp-poi-box-2 yi al anlamına geliyor.\n",
    "for i in soup.find_all(\"div\",{\"class\":\"yp-poi-box-2\"}):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İşte bu kadar ! Bir sonraki derste ***IMDB Top 250*** projemizi yazmaya başlayacağız. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
